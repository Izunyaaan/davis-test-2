<!DOCTYPE html>
<html lang="en">

    <head>
        <meta charset="UTF-8">
        <meta name="description" content="DAVIS Test 2 Part A">
        <meta name="author" content="Faiz 'Izunyan' Sufrikhan">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <script type="text/javascript" async=""
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
            </script>
        <title>Faiz Answers for DAVIS Test 2 Part A</title>
        <link rel="stylesheet"
            href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
        <style>
            html,
            body {
                padding: 0;
                margin: 0;
                height: 100vh;
            }

            body {
                background-color: black;
                color: aliceblue;
                margin-inline: auto;
                display: flex;
                flex-direction: row;
                flex-wrap: wrap;
                box-sizing: border-box;
                justify-content: space-around;
            }

            header {
                width: 100vw;
                margin-bottom: 1rem;
            }

            nav {
                width: 22vw;
                position: fixed;
                top: 4rem;
                left: 0.5vw;
            }

            article {
                margin-left: 23vw;
                width: 75vw;
            }

            footer {
                margin-top: 1rem;
                border-top: 0.4ch solid wheat;
                width: 100vw;
                padding: 1rem;
            }

            fieldset {
                background-color: whitesmoke;
                color: black;
                margin-bottom: 3rem;
                min-height: 100vh;
            }

            legend {
                background-color: aliceblue;
                outline: 1px solid black;
            }

            .centered {
                text-align: center;
            }

            .references {
                font-style: italic;
                outline: 1px solid black;
                padding: 1rem;
                background-color: rgba(112, 128, 144, 0.462);
                color: black;
                font-weight: bolder;
            }

            .references a {
                color: black;
            }

            nav a {
                color: whitesmoke;
                display: block;
                outline: 1px solid white;
                padding: 0.3rem;
                border-left: 0.5ch solid wheat;
            }

            nav a:hover {
                background-color: rgba(240, 248, 255, 0.407);
                color: black;
                font-weight: bolder;
            }

            .activeLink {

                background-color: rgba(240, 248, 255, 0.407);
                color: black;
                font-weight: bolder;
            }

            .fit {
                width: 86%;
                outline: black 1px solid;
            }
        </style>
    </head>

    <body>
        <header class="centered">
            <h1>Data Analytics and Visualization Concepts (50 Marks)</h1>
        </header>
        <nav>
            <p><a href="/index.html"><i class="fa fa-home"></i>Back to Home</a></p>
            <p><a href="#Q1" class="nav">Question 1</a></p>
            <p><a href="#Q2" class="nav">Question 2</a></p>
            <p><a href="#Q3" class="nav">Question 3</a></p>
            <p><a href="#Q4" class="nav">Question 4</a></p>
            <p><a href="#Q5" class="nav">Question 5</a></p>
            <p><a href="#Q6" class="nav">Question 6</a></p>
            <p><a href="#Q7" class="nav">Question 7</a></p>
        </nav>
        <article>
            <fieldset id="Q1">
                <legend>1. Describe the 'Bagging' technique. [7 marks]</legend>
                <p>
                    Bagging is a type of ensemble learning. Ensemble learning is taking the results of multiple models
                    and
                    returns one result based on this collection. Bagging is also known as bootstrap aggregation. It is a
                    technique that reduces variance in a noisy dataset.
                </p>
                <p>
                    How it works is we create sample sets from the training data. It is typically smaller than the total
                    length of the training set. The sample sets are created by randomly picking data points from the
                    training dataset. This process is purely random and the selected data point still remains in the
                    training dataset. This means that it can be picked and added to the sample set again if the RNG
                    picks it
                    again. For example:
                </p>
                <p>
                    Assume the training dataset is {1,2,3,4,5,6,7,8}.<br>
                    We now want a subset of length 3. We randomly pick one data point from the training data and got 2.
                    We
                    randomly pick again and got 7. And we randomly pick again but the rng tells us to pick 2. Thus the
                    sample is now {2,7,2}.
                </p>
                <p>
                    This technique of randomly picking data points and allowing the same data points to be chosen more
                    than
                    once is called <strong>resampling with replacement.</strong> This process of creating bootstrap
                    sample
                    sets is where the <em>bootstrap</em> in bootstrap aggregation comes from.
                </p>
                <p>
                    Now that we have multiple sample sets, we can use them to train weak learners such as logistic
                    regression. Typically we training using the same weak learner. So if we train one sample set with
                    logistic regression, the other sample sets are also trained using logistic regression.
                </p>
                <p>
                    We now combine the results that we get from the weak learners. This is typically done by averaging.
                    This
                    aggregating process is where the <em>aggregation</em> in bootstrap aggregation comes from. This
                    averaging is how bagging reduces variance in a noisy dataset. And by using purely random datasets,
                    overfitting is also reduced.
                </p>
                <p class="centered">
                    <img src="https://cdn.corporatefinanceinstitute.com/assets/bagging.png"
                        alt="Chart illustrating how bagging works" class="fit" />
                </p>
                <p class="centered">
                    <em>This image illustrates how bagging works.</em>
                </p>
                <div class="references">
                    <p>
                        References:
                    </p>
                    <ul>
                        <li>Lecture notes</li>
                        <li><a
                                href="https://corporatefinanceinstitute.com/resources/knowledge/other/bagging-bootstrap-aggregation/">CFI</a>
                        </li>
                        <li><a
                                href="https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205">Rocca
                                J. (2019)</a></li>
                        <li><a
                                href="https://www.ibm.com/cloud/learn/bagging#:~:text=Bagging%2C%20also%20known%20as%20bootstrap,be%20chosen%20more%20than%20once.">IBM</a>
                        </li>
                        <li><a href="https://www.youtube.com/watch?v=RtrBtAKwcxQ">codebasics</a></li>
                    </ul>
                </div>

            </fieldset>
            <fieldset id="Q2">
                <legend>2. Describe the 'Adaboost' technique. [7 marks]</legend>
                <p>
                    AdaBoost, which is short for Adaptive Boosting, is another ensemble learning technique. It is based
                    on the boosting algorithm which is widely used for solving binary classification problems
                    apparently.
                    Boosting was first presented in 1997 by Freund and Schapire.
                </p>
                <p>
                    Boosting is basically building models repeatedly, each repetition boosting the accuracy of the next
                    model (thus the name), until the final model gives a satisfactory result. This sounds like it would
                    cause overfitting, but by being careful and employing techniques such as cross validation, using
                    small learning rates and others.
                </p>
                <p>
                    The AdaBoost algorithm works by assigning weights to data points. On the first run, all data points
                    have equal weights. This is then fed into a model and once we get an output, the weights of the data
                    points that were misclassified are increased. This affectively means that these points have a higher
                    importance when fed into the next model. By adapting these weights to perform the boosting is why
                    this technique is called Adaptive Boosting.
                </p>
                <p>
                    The final step is to make a final model using the weighted average of the individual models to
                    aggregate the findings (it is an ensemble learning technique).
                </p>
                <p class="centered">
                    <img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2021/03/Screenshot-from-2021-03-26-07-45-11.png"
                        alt="how average weighting works" class="fit" />
                </p>
                <p class="centered"><em>This image illustrates how the weighted average is found.</em></p>
                <p>The blue shaded area shows the misclassified data points. And we can see the final decision boundary
                    is an average we get from combining all three models.</p>
                <p>
                    According to Saini, A. (2021), AdaBoost is typically used with decision trees with only one split
                    called <strong>Decision Stump</strong>/
                </p>
                <p class="centered">
                    <img src="https://editor.analyticsvidhya.com/uploads/159381.png" alt="illustrate how adaboost works"
                        class="fit" />
                </p>
                <p class="centered">
                    <em>An image illustrating how AdaBoost works</em>
                </p>
                <div class="references">
                    <p>References:</p>
                    <ul>
                        <li>Lecture Notes</li>
                        <li><a
                                href="https://www.analyticsvidhya.com/blog/2021/09/adaboost-algorithm-a-complete-guide-for-beginners/">Saini.
                                A. (2019)</a></li>
                        <li><a
                                href="https://www.analyticsvidhya.com/blog/2021/03/introduction-to-adaboost-algorithm-with-python-implementation/">shipra_saxenna
                                (2021)</a></li>
                        <li><a
                                href="https://stats.stackexchange.com/questions/20714/does-ensembling-boosting-cause-overfitting#:~:text=All%20machine%20learning%20algorithms%2C%20boosting,any%20algorithm%20that%20you%20apply.">Parkes.
                                S. (2012)</a></li>
                    </ul>
                </div>
            </fieldset>
            <fieldset id="Q3">
                <legend>
                    3. Define the following representations:[6 marks]
                    <ul>
                        <li>Box plot</li>
                        <li>Distribution plot</li>
                    </ul>
                    What kind of information can they express?
                </legend>
            </fieldset>
            <fieldset id="Q4">
                <legend>4. Compare and Contrast the following data representation approaches: Maps, Tables and Graphs.
                    [9
                    marks]</legend>
            </fieldset>
            <fieldset id="Q5">
                <legend>5. Data visualization is a graphical representation that contains the information and the data.
                    Discuss
                    in
                    your own words why graphical representation could be more expressive than representing information
                    using
                    numbers? Give examples to supports your arguments. [8 marks]</legend>
            </fieldset>
            <fieldset id="Q6">
                <legend>6. D3 stands for Data-Driven-Documents, D3 is a powerful data visualization tool by many.
                    Describe
                    three
                    salient features of D3 over traditional graphing tools. [6 marks]</legend>
            </fieldset>
            <fieldset id="Q7">
                <legend>7. Explain ethical issues that may be of concerns when designing visualization e.g., concerns
                    regarding
                    genders, religions, races, or other dimensions that you can think of (open question). [7 marks]
                </legend>
            </fieldset>
        </article>
        <footer class="centered">
            <strong>Written By:</strong> <u>Faiz 'Izunyan' Sufrikhan</u><br>
            <strong>Written For:</strong> <u>Dr. Somnuk Phon-Amnuaisuk</u><br>
            <strong>Written On:</strong> <u>19<sup>th</sup> April 2022</u>
        </footer>
    </body>
    <script>
        answers = document.querySelectorAll('fieldset');
        links = document.querySelectorAll('.nav');

        window.onscroll = () => {
            let current = ""

            answers.forEach((answer, index) => {
                const answerTop = answer.offsetTop
                if (pageYOffset >= answerTop - 20) {
                    current = index
                }
            });

            links.forEach((link, index) => {
                link.classList.remove("activeLink")
                if (index == current) {
                    link.classList.add("activeLink")
                }
            });
        }
    </script>

</html>